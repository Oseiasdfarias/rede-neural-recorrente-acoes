{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0348a311",
   "metadata": {},
   "source": [
    "# Rede Neural Recorrente usando MultPrevisores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5b5b8f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4d4d4fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregando a base de dados \n",
    "base = pd.read_csv(\"petr4_treinamento.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f0e09605",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1242, 7)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removendo registros com valores faltantes\n",
    "base = base.dropna()\n",
    "base.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d32f60a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# criando a base de dados para treinamento multprevisores\n",
    "base_train = base.iloc[:, 1:7].values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1869e6f7",
   "metadata": {},
   "source": [
    "## Normalizando os valores da base de treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "32e35f09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.76501938, 0.77266112, 0.79682707, 0.76080559, 0.6838135 ,\n",
       "        0.04318274],\n",
       "       [0.7562984 , 0.78187106, 0.79733884, 0.79567784, 0.71590949,\n",
       "        0.0437121 ],\n",
       "       [0.78149225, 0.79253519, 0.82139202, 0.79715132, 0.71726583,\n",
       "        0.05170752],\n",
       "       ...,\n",
       "       [0.57122093, 0.57537562, 0.60696008, 0.58202356, 0.58202349,\n",
       "        0.03369652],\n",
       "       [0.57655039, 0.57489089, 0.60798362, 0.5844794 , 0.58447937,\n",
       "        0.02720006],\n",
       "       [0.57655039, 0.57343674, 0.61310133, 0.5844794 , 0.58447937,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instanciando um objeto do modulo sklearn usado para normalização de dados numéricos\n",
    "normalizador = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "# normalizador para as previsões\n",
    "normalizador_previsoes = MinMaxScaler(feature_range=(0, 1))\n",
    "normalizador_previsoes.fit_transform(base_train[:, 0:1])\n",
    "\n",
    "# Aplicando a normalização dos dados\n",
    "base_train_norm = normalizador.fit_transform(base_train)\n",
    "base_train_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d26949c",
   "metadata": {},
   "source": [
    "## Colocando os previsores em um formato que uma rede neural recorrente possa ser aplicada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ec162755",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listas\n",
    "previsores = []\n",
    "preco_real = []\n",
    "\n",
    "for i in range(90, 1242):\n",
    "    previsores.append(base_train_norm[i-90: i, 0:6])\n",
    "    preco_real.append(base_train_norm[i, 0])\n",
    "\n",
    "# Transformando as listas em array do numpy\n",
    "previsores, preco_real = np.array(previsores), np.array(preco_real)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d49ccb",
   "metadata": {},
   "source": [
    "## Criando o modelo de rede neural recorrente com keras "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d0ffbc8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciando um objeto Squential, utilizado como estrutura para construir o modelo de rede neural recorrente\n",
    "regressor = Sequential()\n",
    "\n",
    "# Criando a primeira camada LSTM \n",
    "regressor.add(LSTM(units = 100, return_sequences = True, input_shape = (previsores.shape[1], 6)))\n",
    "regressor.add(Dropout(0.3))\n",
    "\n",
    "regressor.add(LSTM(units = 50, return_sequences = True))\n",
    "regressor.add(Dropout(0.3))\n",
    "\n",
    "regressor.add(LSTM(units = 50, return_sequences = True))\n",
    "regressor.add(Dropout(0.3))\n",
    "\n",
    "regressor.add(LSTM(units = 50))\n",
    "regressor.add(Dropout(0.3))\n",
    "\n",
    "regressor.add(Dense(units = 1, activation = \"sigmoid\"))\n",
    "\n",
    "# Compilando o modelo\n",
    "regressor.compile(optimizer = \"rmsprop\",\n",
    "                  loss = \"mean_squared_error\",\n",
    "                 metrics = [\"mean_absolute_error\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad806ef",
   "metadata": {},
   "source": [
    "### Treinando o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "25ca852e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "36/36 [==============================] - 30s 505ms/step - loss: 0.0292 - mean_absolute_error: 0.1340\n",
      "\n",
      "Epoch 00001: loss improved from inf to 0.01926, saving model to pesos.h5\n",
      "Epoch 2/100\n",
      "36/36 [==============================] - 18s 502ms/step - loss: 0.0074 - mean_absolute_error: 0.0680\n",
      "\n",
      "Epoch 00002: loss improved from 0.01926 to 0.00730, saving model to pesos.h5\n",
      "Epoch 3/100\n",
      "36/36 [==============================] - 17s 486ms/step - loss: 0.0061 - mean_absolute_error: 0.0619\n",
      "\n",
      "Epoch 00003: loss improved from 0.00730 to 0.00602, saving model to pesos.h5\n",
      "Epoch 4/100\n",
      "36/36 [==============================] - 17s 460ms/step - loss: 0.0050 - mean_absolute_error: 0.0543\n",
      "\n",
      "Epoch 00004: loss improved from 0.00602 to 0.00498, saving model to pesos.h5\n",
      "Epoch 5/100\n",
      "36/36 [==============================] - 11s 290ms/step - loss: 0.0047 - mean_absolute_error: 0.0554\n",
      "\n",
      "Epoch 00005: loss improved from 0.00498 to 0.00471, saving model to pesos.h5\n",
      "Epoch 6/100\n",
      "36/36 [==============================] - 12s 339ms/step - loss: 0.0044 - mean_absolute_error: 0.0528\n",
      "\n",
      "Epoch 00006: loss improved from 0.00471 to 0.00420, saving model to pesos.h5\n",
      "Epoch 7/100\n",
      "36/36 [==============================] - 14s 377ms/step - loss: 0.0038 - mean_absolute_error: 0.0473\n",
      "\n",
      "Epoch 00007: loss improved from 0.00420 to 0.00367, saving model to pesos.h5\n",
      "Epoch 8/100\n",
      "36/36 [==============================] - 13s 354ms/step - loss: 0.0037 - mean_absolute_error: 0.0470\n",
      "\n",
      "Epoch 00008: loss improved from 0.00367 to 0.00357, saving model to pesos.h5\n",
      "Epoch 9/100\n",
      "36/36 [==============================] - 15s 428ms/step - loss: 0.0037 - mean_absolute_error: 0.0472\n",
      "\n",
      "Epoch 00009: loss improved from 0.00357 to 0.00334, saving model to pesos.h5\n",
      "Epoch 10/100\n",
      "36/36 [==============================] - 12s 325ms/step - loss: 0.0031 - mean_absolute_error: 0.0433\n",
      "\n",
      "Epoch 00010: loss improved from 0.00334 to 0.00289, saving model to pesos.h5\n",
      "Epoch 11/100\n",
      "36/36 [==============================] - 11s 312ms/step - loss: 0.0028 - mean_absolute_error: 0.0413\n",
      "\n",
      "Epoch 00011: loss improved from 0.00289 to 0.00275, saving model to pesos.h5\n",
      "Epoch 12/100\n",
      "36/36 [==============================] - 15s 420ms/step - loss: 0.0032 - mean_absolute_error: 0.0435\n",
      "\n",
      "Epoch 00012: loss did not improve from 0.00275\n",
      "Epoch 13/100\n",
      "36/36 [==============================] - 15s 402ms/step - loss: 0.0027 - mean_absolute_error: 0.0398\n",
      "\n",
      "Epoch 00013: loss improved from 0.00275 to 0.00254, saving model to pesos.h5\n",
      "Epoch 14/100\n",
      "36/36 [==============================] - 13s 362ms/step - loss: 0.0029 - mean_absolute_error: 0.0425\n",
      "\n",
      "Epoch 00014: loss did not improve from 0.00254\n",
      "Epoch 15/100\n",
      "36/36 [==============================] - 11s 302ms/step - loss: 0.0021 - mean_absolute_error: 0.0348\n",
      "\n",
      "Epoch 00015: loss improved from 0.00254 to 0.00218, saving model to pesos.h5\n",
      "Epoch 16/100\n",
      "36/36 [==============================] - 10s 276ms/step - loss: 0.0023 - mean_absolute_error: 0.0377\n",
      "\n",
      "Epoch 00016: loss did not improve from 0.00218\n",
      "Epoch 17/100\n",
      "36/36 [==============================] - 10s 279ms/step - loss: 0.0025 - mean_absolute_error: 0.0385\n",
      "\n",
      "Epoch 00017: loss did not improve from 0.00218\n",
      "Epoch 18/100\n",
      "36/36 [==============================] - 10s 278ms/step - loss: 0.0025 - mean_absolute_error: 0.0387\n",
      "\n",
      "Epoch 00018: loss did not improve from 0.00218\n",
      "Epoch 19/100\n",
      "36/36 [==============================] - 10s 278ms/step - loss: 0.0021 - mean_absolute_error: 0.0351\n",
      "\n",
      "Epoch 00019: loss improved from 0.00218 to 0.00212, saving model to pesos.h5\n",
      "Epoch 20/100\n",
      "36/36 [==============================] - 10s 279ms/step - loss: 0.0018 - mean_absolute_error: 0.0332\n",
      "\n",
      "Epoch 00020: loss improved from 0.00212 to 0.00187, saving model to pesos.h5\n",
      "Epoch 21/100\n",
      "36/36 [==============================] - 10s 272ms/step - loss: 0.0020 - mean_absolute_error: 0.0342\n",
      "\n",
      "Epoch 00021: loss did not improve from 0.00187\n",
      "Epoch 22/100\n",
      "36/36 [==============================] - 10s 277ms/step - loss: 0.0020 - mean_absolute_error: 0.0334\n",
      "\n",
      "Epoch 00022: loss improved from 0.00187 to 0.00184, saving model to pesos.h5\n",
      "Epoch 23/100\n",
      "36/36 [==============================] - 10s 281ms/step - loss: 0.0018 - mean_absolute_error: 0.0327\n",
      "\n",
      "Epoch 00023: loss improved from 0.00184 to 0.00183, saving model to pesos.h5\n",
      "Epoch 24/100\n",
      "36/36 [==============================] - 10s 288ms/step - loss: 0.0019 - mean_absolute_error: 0.0344\n",
      "\n",
      "Epoch 00024: loss improved from 0.00183 to 0.00174, saving model to pesos.h5\n",
      "Epoch 25/100\n",
      "36/36 [==============================] - 12s 324ms/step - loss: 0.0019 - mean_absolute_error: 0.0327\n",
      "\n",
      "Epoch 00025: loss did not improve from 0.00174\n",
      "Epoch 26/100\n",
      "36/36 [==============================] - 13s 365ms/step - loss: 0.0019 - mean_absolute_error: 0.0325\n",
      "\n",
      "Epoch 00026: loss did not improve from 0.00174\n",
      "Epoch 27/100\n",
      "36/36 [==============================] - 13s 358ms/step - loss: 0.0018 - mean_absolute_error: 0.0329\n",
      "\n",
      "Epoch 00027: loss did not improve from 0.00174\n",
      "Epoch 28/100\n",
      "36/36 [==============================] - 18s 491ms/step - loss: 0.0014 - mean_absolute_error: 0.0289\n",
      "\n",
      "Epoch 00028: loss improved from 0.00174 to 0.00167, saving model to pesos.h5\n",
      "Epoch 29/100\n",
      "36/36 [==============================] - 16s 449ms/step - loss: 0.0016 - mean_absolute_error: 0.0298\n",
      "\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "\n",
      "Epoch 00029: loss improved from 0.00167 to 0.00164, saving model to pesos.h5\n",
      "Epoch 30/100\n",
      "36/36 [==============================] - 14s 385ms/step - loss: 0.0011 - mean_absolute_error: 0.0250\n",
      "\n",
      "Epoch 00030: loss improved from 0.00164 to 0.00113, saving model to pesos.h5\n",
      "Epoch 31/100\n",
      "36/36 [==============================] - 10s 268ms/step - loss: 0.0011 - mean_absolute_error: 0.0247\n",
      "\n",
      "Epoch 00031: loss did not improve from 0.00113\n",
      "Epoch 32/100\n",
      "36/36 [==============================] - 9s 246ms/step - loss: 9.8590e-04 - mean_absolute_error: 0.0236\n",
      "\n",
      "Epoch 00032: loss did not improve from 0.00113\n",
      "Epoch 33/100\n",
      "36/36 [==============================] - 8s 233ms/step - loss: 0.0011 - mean_absolute_error: 0.0252\n",
      "\n",
      "Epoch 00033: loss did not improve from 0.00113\n",
      "Epoch 34/100\n",
      "36/36 [==============================] - 9s 235ms/step - loss: 0.0012 - mean_absolute_error: 0.0249\n",
      "\n",
      "Epoch 00034: loss did not improve from 0.00113\n",
      "Epoch 35/100\n",
      "36/36 [==============================] - 8s 231ms/step - loss: 0.0011 - mean_absolute_error: 0.0237\n",
      "\n",
      "Epoch 00035: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "\n",
      "Epoch 00035: loss improved from 0.00113 to 0.00109, saving model to pesos.h5\n",
      "Epoch 36/100\n",
      "36/36 [==============================] - 9s 242ms/step - loss: 0.0010 - mean_absolute_error: 0.0234\n",
      "\n",
      "Epoch 00036: loss improved from 0.00109 to 0.00107, saving model to pesos.h5\n",
      "Epoch 37/100\n",
      "36/36 [==============================] - 10s 277ms/step - loss: 0.0011 - mean_absolute_error: 0.0246\n",
      "\n",
      "Epoch 00037: loss improved from 0.00107 to 0.00106, saving model to pesos.h5\n",
      "Epoch 38/100\n",
      "36/36 [==============================] - 10s 272ms/step - loss: 9.6559e-04 - mean_absolute_error: 0.0235\n",
      "\n",
      "Epoch 00038: loss improved from 0.00106 to 0.00103, saving model to pesos.h5\n",
      "Epoch 39/100\n",
      "36/36 [==============================] - 9s 239ms/step - loss: 0.0011 - mean_absolute_error: 0.0245\n",
      "\n",
      "Epoch 00039: loss improved from 0.00103 to 0.00103, saving model to pesos.h5\n",
      "Epoch 40/100\n",
      "36/36 [==============================] - 9s 239ms/step - loss: 0.0012 - mean_absolute_error: 0.0255\n",
      "\n",
      "Epoch 00040: loss did not improve from 0.00103\n",
      "Epoch 41/100\n",
      "36/36 [==============================] - 11s 298ms/step - loss: 0.0011 - mean_absolute_error: 0.0250\n",
      "\n",
      "Epoch 00041: loss did not improve from 0.00103\n",
      "Epoch 42/100\n",
      "36/36 [==============================] - 18s 490ms/step - loss: 0.0010 - mean_absolute_error: 0.0236\n",
      "\n",
      "Epoch 00042: loss did not improve from 0.00103\n",
      "Epoch 43/100\n",
      "36/36 [==============================] - 15s 408ms/step - loss: 0.0011 - mean_absolute_error: 0.0244\n",
      "\n",
      "Epoch 00043: loss did not improve from 0.00103\n",
      "Epoch 44/100\n",
      "36/36 [==============================] - 14s 397ms/step - loss: 0.0011 - mean_absolute_error: 0.0245\n",
      "\n",
      "Epoch 00044: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "\n",
      "Epoch 00044: loss improved from 0.00103 to 0.00102, saving model to pesos.h5\n",
      "Epoch 45/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 20s 558ms/step - loss: 0.0012 - mean_absolute_error: 0.0258\n",
      "\n",
      "Epoch 00045: loss did not improve from 0.00102\n",
      "Epoch 46/100\n",
      "36/36 [==============================] - 22s 611ms/step - loss: 0.0012 - mean_absolute_error: 0.0242\n",
      "\n",
      "Epoch 00046: loss did not improve from 0.00102\n",
      "Epoch 47/100\n",
      "36/36 [==============================] - 20s 563ms/step - loss: 0.0011 - mean_absolute_error: 0.0241\n",
      "\n",
      "Epoch 00047: loss improved from 0.00102 to 0.00102, saving model to pesos.h5\n",
      "Epoch 48/100\n",
      "36/36 [==============================] - 16s 447ms/step - loss: 0.0011 - mean_absolute_error: 0.0237\n",
      "\n",
      "Epoch 00048: loss did not improve from 0.00102\n",
      "Epoch 49/100\n",
      "36/36 [==============================] - 15s 425ms/step - loss: 0.0011 - mean_absolute_error: 0.0248\n",
      "\n",
      "Epoch 00049: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n",
      "\n",
      "Epoch 00049: loss improved from 0.00102 to 0.00099, saving model to pesos.h5\n",
      "Epoch 50/100\n",
      "36/36 [==============================] - 16s 449ms/step - loss: 9.7132e-04 - mean_absolute_error: 0.0230\n",
      "\n",
      "Epoch 00050: loss did not improve from 0.00099\n",
      "Epoch 51/100\n",
      "36/36 [==============================] - 12s 331ms/step - loss: 0.0010 - mean_absolute_error: 0.0240\n",
      "\n",
      "Epoch 00051: loss did not improve from 0.00099\n",
      "Epoch 52/100\n",
      "36/36 [==============================] - 9s 248ms/step - loss: 0.0010 - mean_absolute_error: 0.0239\n",
      "\n",
      "Epoch 00052: loss did not improve from 0.00099\n",
      "Epoch 53/100\n",
      "36/36 [==============================] - 10s 265ms/step - loss: 0.0010 - mean_absolute_error: 0.0237\n",
      "\n",
      "Epoch 00053: loss did not improve from 0.00099\n",
      "Epoch 54/100\n",
      "36/36 [==============================] - 9s 256ms/step - loss: 0.0011 - mean_absolute_error: 0.0240\n",
      "\n",
      "Epoch 00054: ReduceLROnPlateau reducing learning rate to 3.200000264769187e-07.\n",
      "\n",
      "Epoch 00054: loss did not improve from 0.00099\n",
      "Epoch 55/100\n",
      "36/36 [==============================] - 12s 348ms/step - loss: 0.0011 - mean_absolute_error: 0.0239\n",
      "\n",
      "Epoch 00055: loss did not improve from 0.00099\n",
      "Epoch 56/100\n",
      "36/36 [==============================] - 10s 269ms/step - loss: 0.0010 - mean_absolute_error: 0.0237\n",
      "\n",
      "Epoch 00056: loss did not improve from 0.00099\n",
      "Epoch 57/100\n",
      "36/36 [==============================] - 9s 240ms/step - loss: 0.0010 - mean_absolute_error: 0.0237\n",
      "\n",
      "Epoch 00057: loss did not improve from 0.00099\n",
      "Epoch 58/100\n",
      "36/36 [==============================] - 8s 222ms/step - loss: 9.1314e-04 - mean_absolute_error: 0.0227\n",
      "\n",
      "Epoch 00058: loss improved from 0.00099 to 0.00096, saving model to pesos.h5\n",
      "Epoch 59/100\n",
      "36/36 [==============================] - 8s 218ms/step - loss: 0.0011 - mean_absolute_error: 0.0239\n",
      "\n",
      "Epoch 00059: ReduceLROnPlateau reducing learning rate to 6.400000529538374e-08.\n",
      "\n",
      "Epoch 00059: loss did not improve from 0.00096\n",
      "Epoch 60/100\n",
      "36/36 [==============================] - 8s 229ms/step - loss: 0.0010 - mean_absolute_error: 0.0236\n",
      "\n",
      "Epoch 00060: loss improved from 0.00096 to 0.00096, saving model to pesos.h5\n",
      "Epoch 61/100\n",
      "36/36 [==============================] - 8s 221ms/step - loss: 9.9929e-04 - mean_absolute_error: 0.0232\n",
      "\n",
      "Epoch 00061: loss did not improve from 0.00096\n",
      "Epoch 62/100\n",
      "36/36 [==============================] - 8s 220ms/step - loss: 0.0012 - mean_absolute_error: 0.0242\n",
      "\n",
      "Epoch 00062: loss did not improve from 0.00096\n",
      "Epoch 63/100\n",
      "36/36 [==============================] - 8s 219ms/step - loss: 9.2615e-04 - mean_absolute_error: 0.0220\n",
      "\n",
      "Epoch 00063: loss did not improve from 0.00096\n",
      "Epoch 64/100\n",
      "36/36 [==============================] - 8s 219ms/step - loss: 0.0010 - mean_absolute_error: 0.0236\n",
      "\n",
      "Epoch 00064: ReduceLROnPlateau reducing learning rate to 1.2800001059076749e-08.\n",
      "\n",
      "Epoch 00064: loss did not improve from 0.00096\n",
      "Epoch 65/100\n",
      "36/36 [==============================] - 8s 220ms/step - loss: 0.0011 - mean_absolute_error: 0.0236\n",
      "\n",
      "Epoch 00065: loss did not improve from 0.00096\n",
      "Epoch 66/100\n",
      "36/36 [==============================] - 8s 220ms/step - loss: 9.6943e-04 - mean_absolute_error: 0.0231\n",
      "\n",
      "Epoch 00066: loss did not improve from 0.00096\n",
      "Epoch 67/100\n",
      "36/36 [==============================] - 8s 218ms/step - loss: 9.8880e-04 - mean_absolute_error: 0.0239\n",
      "\n",
      "Epoch 00067: loss did not improve from 0.00096\n",
      "Epoch 68/100\n",
      "36/36 [==============================] - 8s 219ms/step - loss: 0.0011 - mean_absolute_error: 0.0238\n",
      "\n",
      "Epoch 00068: loss did not improve from 0.00096\n",
      "Epoch 69/100\n",
      "36/36 [==============================] - 8s 218ms/step - loss: 0.0011 - mean_absolute_error: 0.0238\n",
      "\n",
      "Epoch 00069: ReduceLROnPlateau reducing learning rate to 2.5600002118153498e-09.\n",
      "\n",
      "Epoch 00069: loss did not improve from 0.00096\n",
      "Epoch 70/100\n",
      "36/36 [==============================] - 8s 217ms/step - loss: 9.2572e-04 - mean_absolute_error: 0.0221\n",
      "\n",
      "Epoch 00070: loss did not improve from 0.00096\n",
      "Epoch 00070: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f231419fb20>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Configurando os hiperparâmetros do modelo\n",
    "es = EarlyStopping(monitor=\"loss\", min_delta=1e-10, patience=10, verbose=1)\n",
    "rlr = ReduceLROnPlateau(monitor = \"loss\", factor = 0.2, patience = 5, verbose = 1)\n",
    "mcp = ModelCheckpoint(filepath=\"pesos.h5\", monitor=\"loss\", save_best_only=True, verbose = 1)\n",
    "\n",
    "# Treinando o modelo\n",
    "regressor.fit(previsores,\n",
    "              preco_real,\n",
    "              epochs=100,\n",
    "              batch_size = 32,\n",
    "              callbacks=[es, rlr, mcp])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b0dd03",
   "metadata": {},
   "source": [
    "# Carregando base de dados de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a1c89f07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>16.190001</td>\n",
       "      <td>16.549999</td>\n",
       "      <td>16.190001</td>\n",
       "      <td>16.549999</td>\n",
       "      <td>16.516966</td>\n",
       "      <td>33461800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>16.490000</td>\n",
       "      <td>16.719999</td>\n",
       "      <td>16.370001</td>\n",
       "      <td>16.700001</td>\n",
       "      <td>16.666668</td>\n",
       "      <td>55940900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-04</td>\n",
       "      <td>16.780001</td>\n",
       "      <td>16.959999</td>\n",
       "      <td>16.620001</td>\n",
       "      <td>16.730000</td>\n",
       "      <td>16.696608</td>\n",
       "      <td>37064900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-05</td>\n",
       "      <td>16.700001</td>\n",
       "      <td>16.860001</td>\n",
       "      <td>16.570000</td>\n",
       "      <td>16.830000</td>\n",
       "      <td>16.796408</td>\n",
       "      <td>26958200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-08</td>\n",
       "      <td>16.740000</td>\n",
       "      <td>17.030001</td>\n",
       "      <td>16.709999</td>\n",
       "      <td>17.030001</td>\n",
       "      <td>16.996010</td>\n",
       "      <td>28400000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date       Open       High        Low      Close  Adj Close    Volume\n",
       "0  2018-01-02  16.190001  16.549999  16.190001  16.549999  16.516966  33461800\n",
       "1  2018-01-03  16.490000  16.719999  16.370001  16.700001  16.666668  55940900\n",
       "2  2018-01-04  16.780001  16.959999  16.620001  16.730000  16.696608  37064900\n",
       "3  2018-01-05  16.700001  16.860001  16.570000  16.830000  16.796408  26958200\n",
       "4  2018-01-08  16.740000  17.030001  16.709999  17.030001  16.996010  28400000"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_test = pd.read_csv(\"petr4_teste.csv\")\n",
    "base_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "47db8d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pegando os valores de da coluna Open\n",
    "preco_real_test = base_test.iloc[:, 1:2].values\n",
    "\n",
    "# Concatenando os dados de teste com os dados de treino\n",
    "frames = [base, base_test]\n",
    "base_completa = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b80ea3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removendo a coluna date\n",
    "base_completa = base_completa.drop(\"Date\", axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "774b234f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# colocando os dados no formato  correto para a rede neural recorrente\n",
    "entradas = base_completa[len(base_completa) - len(base_test) - 90: ].values\n",
    "\n",
    "# Normalizando as entradas\n",
    "entradas = normalizador.transform(entradas)\n",
    "\n",
    "x_test = []\n",
    "for i in range(90, 112):\n",
    "    x_test.append(entradas[i-90:i, 0:6])\n",
    "\n",
    "# Convertendo para um objeto numpy array\n",
    "x_test = np.array(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3cee5155",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22, 90, 6)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f635a7",
   "metadata": {},
   "source": [
    "# Fazendo as previsões usando o modelo treinado "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "39d66fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtendo as previsões\n",
    "previsoes = regressor.predict(x_test)\n",
    "\n",
    "# desfazendo a normalização aplicada as dados anteriormente, apra obter os valores reais \n",
    "previsoes = normalizador_previsoes.inverse_transform(previsoes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe727d8",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e00690a3",
   "metadata": {},
   "source": [
    "## Visoalizando os resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1e807ed9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17.693117"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "previsoes.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b3d34d16",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17.87454563636364"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preco_real_test.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6b081de5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plotando os gráficos das previsões e do valor real\n",
    "plt.plot(preco_real_test, color=\"red\", label= \"Preço real\")\n",
    "plt.plot(previsoes, color=\"blue\", label=\"Previsões\")\n",
    "plt.title(\"Previsão dos preços das ações\")\n",
    "plt.xlabel(\"Tempo\")\n",
    "plt.ylabel(\"Valor Yahoo\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda3e216",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
